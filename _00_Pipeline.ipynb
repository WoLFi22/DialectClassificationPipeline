{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c650708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins import projector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf7515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full._01_Data_Augmentation import augment\n",
    "\n",
    "from ipynb.fs.full._02_Train_Val_Test import create_speaker_DF\n",
    "from ipynb.fs.full._02_Train_Val_Test import choose, choose_train_only\n",
    "\n",
    "from ipynb.fs.full._03_Data import create_data\n",
    "from ipynb.fs.full._03_Data  import getAbsoluteCounts\n",
    "\n",
    "from ipynb.fs.full._04_Model import do_all, do_all_train, do_all_test\n",
    "\n",
    "from ipynb.fs.full._05_Eval import boxplot\n",
    "from ipynb.fs.full._05_Eval import speakerFalse\n",
    "from ipynb.fs.full._05_Eval import confusionMatrix\n",
    "from ipynb.fs.full._05_Eval import weighted_f1\n",
    "from ipynb.fs.full._05_Eval import combined_scores\n",
    "from ipynb.fs.full._05_Eval import plot_dialect_boxplots_test\n",
    "from ipynb.fs.full._05_Eval import plot_dialect_predictions\n",
    "from ipynb.fs.full._05_Eval import plot_dialect_predictions_samples\n",
    "\n",
    "from ipynb.fs.full._06_Compare import boxplot_diff\n",
    "from ipynb.fs.full._06_Compare import significant\n",
    "from ipynb.fs.full._06_Compare import raincloud_diff\n",
    "from ipynb.fs.full._06_Compare import compareConfusionMatrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a5cc79",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43c3c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general Path of all Audios\n",
    "general_path = \"...\"\n",
    "# name of folder inside general_pah for Audios\n",
    "name = '...'\n",
    "data_path = general_path + name\n",
    "# name of Augmentation\n",
    "# Keywords: 'best'->SeR and FM, 'shifting_pitch', 'segment_removal', 'background_noise'\n",
    "# 'segment_swap', 'volume_confusion', 'time_reversing', 'time_stretching', 'speed_confusion', 'time_masking'\n",
    "# 'frequency_masking', 'frequency_swap', 'frequency_insertion', 'speaker_insertion'\n",
    "name_aug = ''\n",
    "data_path_aug = general_path + name_aug\n",
    "# name of folder inside general_pah for testing Audios\n",
    "name_test = \"not_used\"\n",
    "data_path_test = general_path + name_test\n",
    "# name of baseline to compare with (there should be a pkl with the name './Results_' + name_base)\n",
    "name_base = ''\n",
    "\n",
    "\n",
    "# number of augmented files per original\n",
    "aug_num = 6\n",
    "# percentage for augmentation per file\n",
    "aug_perc = 1.0\n",
    "# segment length for each augmentation\n",
    "aug_len = 1.0\n",
    "\n",
    "# length of one segment\n",
    "audio_length = 10.0\n",
    "# what are the maximal seconds for one speaker/dialect (must be a multiple of audio_length or None)\n",
    "# can only be used with augmentation, bc augmented_files get reduced\n",
    "max_length_speaker = None #x*audio_length\n",
    "max_length_dialect = None #y*audio_length\n",
    "\n",
    "#model path for extracting embeddings\n",
    "model_path = \"C:\\\\Users\\\\Lea\\\\Desktop\\\\Doktor\\\\Models\\\\trillsson4\"\n",
    "# learning rate\n",
    "lr = 0.0005\n",
    "# dropout rate\n",
    "dr = 0.2\n",
    "# units dense layer\n",
    "units = 128\n",
    "# size of one batch for trillsson Model\n",
    "batch_size_embedding = 10\n",
    "# size of one batch for CNN\n",
    "batch_size = 1024\n",
    "# L1 regularization parameter used in the dense layers\n",
    "l1 = 0.018\n",
    "# L2 regularization parameter used in the dense layers\n",
    "l2 = 0.01\n",
    "#alpha for LeakyReLU\n",
    "alpha = 0.1\n",
    "# maximal number of epochs\n",
    "max_epochs = 250\n",
    "\n",
    "# number of individual runs\n",
    "runs = 250\n",
    "# pictures of first Epoch\n",
    "first_pictures = True\n",
    "# if not None Speaker for Test and Val will not be random\n",
    "# give a List with List like [['OLALT3', 'HBALT3', 'FLALT2', 'CUXALT4'], ['BLALT1', 'BBALT2', 'CWALT', 'ULALT1']]\n",
    "# each List represents an dialect and the first half of each sublist the Speaker for Testing and the second half the speaker for Validation\n",
    "test = None #[['...', '...'], ['...', '...', '...', '...'], ...]\n",
    "# test with dummy-classificator\n",
    "dummy = False\n",
    "# project to TB\n",
    "tb = True\n",
    "log_dir = '...'\n",
    "# Test different Hyperparameters\n",
    "hyper_test = False\n",
    "# when True the Model gets trained and weights get saved\n",
    "train_only = False\n",
    "# when True the Model makes predictions on Audios in 'data_path_test'\n",
    "test_only = False\n",
    "# value between 0 and 1 used to determine the minimum prediction probability \n",
    "# redictions below this threshold are considered as 'not properly classified'\n",
    "classification_threshold = 0.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a508f61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a path exists\n",
    "def check_valid_path(path, path_name):\n",
    "    if not os.path.isdir(path):\n",
    "        raise ValueError(f\"Invalid path: {path_name} -> {path}\")\n",
    "\n",
    "# Check for test_only\n",
    "if test_only:\n",
    "    if train_only or hyper_test or tb or dummy:\n",
    "        raise ValueError(\"If test_only is True, then train_only, hyper_test, tb, and dummy must be False.\")\n",
    "    if name_base is not None:\n",
    "        raise ValueError(\"If test_only is True, then name_base must be None.\")\n",
    "    if name_aug != '':\n",
    "        raise ValueError(\"If test_only is True, then name_aug must be empty.\")\n",
    "    check_valid_path(data_path_test, \"data_path_test\")\n",
    "\n",
    "# Check for train_only\n",
    "if train_only:\n",
    "    if test_only or hyper_test or dummy:\n",
    "        raise ValueError(\"If train_only is True, then test_only, hyper_test, and dummy must be False.\")\n",
    "    if name_base is not None:\n",
    "        raise ValueError(\"If train_only is True, then name_base must be None.\")\n",
    "    check_valid_path(data_path, \"data_path\")\n",
    "\n",
    "# Check for augmentation\n",
    "if name_aug:\n",
    "    if not (0 <= aug_perc <= 1):\n",
    "        raise ValueError(\"aug_perc must be between 0 and 1.\")\n",
    "    if not (0 <= aug_len <= audio_length):\n",
    "        raise ValueError(\"aug_len must be between 0 and audio_lengh.\")\n",
    "    if aug_num <= 0:\n",
    "        raise ValueError(\"aug_num must be greater than 0.\")\n",
    "    if aug_perc * audio_length < aug_len:\n",
    "        warnings.warn(\"aug_perc * audio_length is less than aug_len.\", UserWarning)\n",
    "\n",
    "# Check for max_length_speaker and max_length_dialect\n",
    "if max_length_speaker is not None and max_length_speaker % audio_length != 0:\n",
    "    raise ValueError(\"max_length_speaker must be a multiple of audio_length.\")\n",
    "if max_length_dialect is not None and max_length_dialect % audio_length != 0:\n",
    "    raise ValueError(\"max_length_dialect must be a multiple of audio_length.\")\n",
    "\n",
    "# Check for hyper_test\n",
    "if hyper_test:\n",
    "    if dummy:\n",
    "        raise ValueError(\"If hyper_test is True, then dummy must be False.\")\n",
    "    if test is None: warnings.warn(\"If hyper_test is True, test should not be None\", UserWarning)\n",
    "\n",
    "print(\"All checks passed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219c7887",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b005604",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (name_aug != ''):\n",
    "    augment(name_aug, data_path, data_path_aug, aug_perc, aug_num, aug_len, audio_length, test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01e33b9",
   "metadata": {},
   "source": [
    "## DF with all Audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c4e968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speaker = create_speaker_DF(data_path, data_path_aug, name_aug, False)\n",
    "df_speaker = pd.read_pickle('./All_Files_.pkl')\n",
    "\n",
    "if test_only:\n",
    "    df_speaker_test = create_speaker_DF(data_path_test, '', '', True)\n",
    "    df_speaker_test = pd.read_pickle('./All_Files_test.pkl')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cf77f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speaker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f9c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_only:\n",
    "    print(df_speaker_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b71736",
   "metadata": {},
   "source": [
    "## Extract Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0f3868",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not test_only):\n",
    "    df_learn = create_data(model_path, audio_length, batch_size_embedding, '', None, None)\n",
    "if (name_aug != ''):\n",
    "    df_learn_aug = create_data(model_path, audio_length, batch_size_embedding, name_aug, max_length_speaker, max_length_dialect)\n",
    "\n",
    "if (test_only):\n",
    "    df_test = create_data(model_path, audio_length, batch_size_embedding, '', None, None, True)\n",
    "    \n",
    "df_learn = pd.read_pickle('./Data_.pkl')\n",
    "if (name_aug != ''):\n",
    "    df_learn_aug = pd.read_pickle('./Data_' + name_aug + '_aug.pkl')\n",
    "else:\n",
    "    df_learn_aug = None\n",
    "if (test_only):\n",
    "    df_test = pd.read_pickle('./Data_test.pkl')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d17528",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929a72c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if (name_aug != ''):\n",
    "    print(df_learn_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab22fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_only:\n",
    "    print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b753cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not test_only):\n",
    "    getAbsoluteCounts(None)\n",
    "if (name_aug != ''):\n",
    "    getAbsoluteCounts(name_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6445ce6b",
   "metadata": {},
   "source": [
    "### Projection of embeddings to TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42a90562",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tb:\n",
    "    labels1 = np.array(df_learn['dialect'].tolist())\n",
    "    len_1 = len(labels1)\n",
    "    labels2 = np.array(df_learn['speaker'].tolist())\n",
    "    embeddings = np.array(df_learn['trillsson'].values.tolist())\n",
    "    if (name_aug != ''):\n",
    "            labels3 = np.array(df_learn_aug['dialect'].tolist())\n",
    "            labels4 = np.array(df_learn_aug['speaker'].tolist())\n",
    "            embeddings2 = np.array(df_learn_aug['trillsson'].values.tolist())\n",
    "            labels1 = np.concatenate((labels1, labels3), axis=None)\n",
    "            labels2 = np.concatenate((labels2, labels4), axis=None)\n",
    "            embeddings = np.concatenate((embeddings, embeddings2), axis=0)\n",
    "\n",
    "    with open(os.path.join(log_dir, 'metadata.tsv'), \"w\") as metadata:\n",
    "        for i in range(0, len(labels1)):\n",
    "            if i >= len_1:\n",
    "                metadata.write(f'{labels1[i] + \"_\" + labels2[i] + \"_aug\"}\\n')\n",
    "            else:\n",
    "                metadata.write(f'{labels1[i] + \"_\" + labels2[i]}\\n')\n",
    "        \n",
    "    embeddings_tensor = tf.Variable(embeddings)\n",
    "\n",
    "    checkpoint = tf.train.Checkpoint(embedding=embeddings_tensor)\n",
    "    checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))\n",
    "\n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "    embedding.metadata_path = 'metadata.tsv'\n",
    "    projector.visualize_embeddings(log_dir, config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f1ea9b",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b36646c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not test_only):\n",
    "    df_learned = pd.DataFrame(columns=['acc_train', 'acc_val', 'acc_test',\n",
    "                                    'loss_train', 'loss_val', 'loss_test',\n",
    "                                    'f1_train', 'f1_val', 'f1_test',\n",
    "                                    'f1_macro_train', 'f1_macro_val', 'f1_macro_test',\n",
    "                                    'f1_w_train', 'f1_w_val', 'f1_w_test',\n",
    "                                    'speaker_val', 'speaker_test', 'false_names', 'false_speaker', 'false_segments_begin',\n",
    "                                    'false_segments_end', 'false_simplified', 'classes_x', 'classes_true', 'y_test_names', \n",
    "                                    'y_test_speaker'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0965f39b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if train_only:\n",
    "    if test is None:\n",
    "        test_val = choose_train_only(df_speaker)\n",
    "        print(test_val)\n",
    "    else:\n",
    "        test_val = test\n",
    "        \n",
    "    list_row, label_mapping = do_all_train(first_pictures, df_learn, df_learn_aug, test_val, name_aug, lr, dr, units, l1, l2, alpha, batch_size, max_epochs) \n",
    "    df_learned.loc[len(df_learned)] = list_row\n",
    "    \n",
    "elif test_only:\n",
    "    predictions, speaker, dialect = do_all_test(df_learn, df_test, lr, dr, units, l1, l2, alpha)\n",
    "    predictions_df = pd.DataFrame({\n",
    "        'predictions': [list(pred) for pred in predictions],\n",
    "        'speaker': speaker,\n",
    "        'dialect': dialect\n",
    "    })\n",
    "    predictions_df.to_csv('predictions.csv', index=False)\n",
    "    predictions_df.to_pickle('predictions.pkl')\n",
    "    \n",
    "else:   \n",
    "    for i in range(0, runs):\n",
    "        print('Iteration ', i, ' of ' + str(runs))\n",
    "    \n",
    "        if test is None:\n",
    "            test_val = choose(df_speaker)\n",
    "            print(test_val)\n",
    "        else:\n",
    "            test_val = test\n",
    "\n",
    "        if (hyper_test):\n",
    "            lr_test = random.uniform(lr[0], lr[1])\n",
    "            dr_test = random.uniform(dr[0], dr[1])\n",
    "            l1_test = random.uniform(l1[0], l1[1])\n",
    "            l2_test = random.uniform(l2[0], l2[1])\n",
    "            alpha_test_num = random.randint(0, len(alpha)-1)\n",
    "            alpha_test = alpha[alpha_test_num]\n",
    "            units_test_num = random.randint(0, len(units)-1)\n",
    "            units_test = units[units_test_num]\n",
    "            batch_size_test_num = random.randint(0, len(batch_size)-1)\n",
    "            batch_size_test = batch_size[batch_size_test_num]\n",
    "      \n",
    "  \n",
    "        if (hyper_test):\n",
    "            list_row, label_mapping = do_all(first_pictures, df_learn, df_learn_aug, test_val, name_aug, i, lr_test, dr_test, units_test, l1_test, l2_test, alpha_test, batch_size_test, tb, log_dir, dummy, max_epochs)  \n",
    "        else:\n",
    "            list_row, label_mapping = do_all(first_pictures, df_learn, df_learn_aug, test_val, name_aug, i, lr, dr, units, l1, l2, alpha, batch_size, tb, log_dir, dummy, max_epochs)   \n",
    "        df_learned.loc[len(df_learned)] = list_row\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d38f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not test_only): \n",
    "    with open('label_mapping.pkl', 'wb') as f:\n",
    "        pkl.dump(label_mapping, f)\n",
    "    df_learned.to_pickle('./Results_' + name + '_' + name_aug + '.pkl')\n",
    "    df_learned.to_csv('./Results_' + name + '_' + name_aug + '.csv',  sep=';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1401cce",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76e01eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('label_mapping.pkl', 'rb') as f:\n",
    "    label_mapping = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d988a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (test_only):\n",
    "    plot_dialect_boxplots_test(predictions_df, df_test, label_mapping)\n",
    "    plot_dialect_predictions(predictions_df, label_mapping)\n",
    "    plot_dialect_predictions_samples(predictions_df, label_mapping)\n",
    "    plot_dialect_predictions_samples(predictions_df, label_mapping, classification_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fcac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not test_only and not train_only):\n",
    "    boxplot('f1_test', name, name_aug)\n",
    "    boxplot('f1_macro_test', name, name_aug)\n",
    "    boxplot('f1_w_test', name, name_aug)\n",
    "    boxplot('acc_test', name, name_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e431948",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not test_only and not train_only):\n",
    "    weighted_f1(name, name_aug, label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "912461c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not test_only and not train_only):\n",
    "    speakerFalse(name, name_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1321db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not test_only and not train_only):\n",
    "    combined_scores(name, name_aug)\n",
    "    confusionMatrix(name, name_aug, label_mapping, True, False)\n",
    "    confusionMatrix(name, name_aug, label_mapping, False, False)\n",
    "    confusionMatrix(name, name_aug, label_mapping, False, True)\n",
    "    confusionMatrix(name, name_aug + \"_combined\", label_mapping, True, False)\n",
    "    confusionMatrix(name, name_aug + \"_combined\", label_mapping, False, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c3b572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (name_base is not None):\n",
    "    compareConfusionMatrix(name, name_aug, name_base, label_mapping, True)\n",
    "    compareConfusionMatrix(name, name_aug, name_base, label_mapping, False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2fc5445",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (name_base is not None):\n",
    "    boxplot_diff('f1_w_test', name_base, name, name_aug)\n",
    "    raincloud_diff('f1_w_test', name_base, name, name_aug)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27db0cef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#compares results base model with new model (two-sided)\n",
    "if (name_base is not None):\n",
    "    U_base, U_aug, p_U, res_T, var_base, var_aug = significant('./Results_' + name_base + '.pkl', './Results_' + name + '_' + name_aug + '.pkl', 'f1_w_test', 'two-sided')\n",
    "    print(\"two-sided U-test: \", f'{p_U:.20f}')\n",
    "    print(\"two-sided T-test: \", f'{res_T.pvalue:.20f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0b9d90",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#tests whether results from base model is less (worse) than from new model\n",
    "if (name_base is not None):\n",
    "    U_base, U_aug, p_U, res_T, var_base, var_aug = significant('./Results_' + name_base + '.pkl', './Results_' + name + '_' + name_aug + '.pkl', 'f1_w_test', 'less')\n",
    "    print(\"one-sided U-test: \", f'{p_U:.20f}')\n",
    "    print(\"two-sided T-test: \", f'{res_T.pvalue:.20f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9095d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
