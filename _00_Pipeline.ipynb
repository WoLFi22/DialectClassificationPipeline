{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c650708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins import projector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf7515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full._01_Data_Augmentation import augment\n",
    "\n",
    "from ipynb.fs.full._02_Train_Val_Test import create_speaker_DF\n",
    "from ipynb.fs.full._02_Train_Val_Test import choose\n",
    "\n",
    "from ipynb.fs.full._03_Data import create_data\n",
    "from ipynb.fs.full._03_Data  import getAbsoluteCounts\n",
    "\n",
    "from ipynb.fs.full._04_Model import do_all\n",
    "\n",
    "from ipynb.fs.full._05_Eval import boxplot\n",
    "from ipynb.fs.full._05_Eval import speakerFalse\n",
    "from ipynb.fs.full._05_Eval import confusionMatrix\n",
    "from ipynb.fs.full._05_Eval import weighted_f1\n",
    "from ipynb.fs.full._05_Eval import combined_scores\n",
    "\n",
    "from ipynb.fs.full._06_Compare import boxplot_diff\n",
    "from ipynb.fs.full._06_Compare import significant\n",
    "from ipynb.fs.full._06_Compare import raincloud_diff\n",
    "from ipynb.fs.full._06_Compare import compareConfusionMatrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a5cc79",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43c3c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general Path of all Audios\n",
    "general_path = \"...\"\n",
    "# name of folder inside general_pah for Audios\n",
    "name = '...'\n",
    "data_path = general_path + name\n",
    "# name of Augmentation\n",
    "# Keywords: 'best'->SeR and FM, 'shifting_pitch', 'segment_removal', 'background_noise'\n",
    "# 'segment_swap', 'volume_confusion', 'time_reversing', 'time_stretching', 'speed_confusion', 'time_masking'\n",
    "# 'frequency_masking', 'frequency_swap', 'frequency_insertion', 'speaker_insertion'\n",
    "name_aug = ''\n",
    "data_path_aug = general_path + name_aug\n",
    "# name of baseline to compare with (there should be a pkl with the name './Results_' + name_base)\n",
    "name_base = ''\n",
    "\n",
    "\n",
    "# number of augmented files per original\n",
    "aug_num = 6\n",
    "# percentage for augmentation per file\n",
    "aug_perc = 1.0\n",
    "# segment length for each augmentation\n",
    "aug_len = 1.0\n",
    "\n",
    "# length of one segment\n",
    "audio_length = 10.0\n",
    "# what are the maximal seconds for one speaker/dialect (must be a multiple of audio_length or None, can't be used with augmentation)\n",
    "max_length_speaker = None #x*audio_length\n",
    "max_length_dialect = None #y*audio_length\n",
    "\n",
    "#model path for extracting embeddings\n",
    "model_path = \"C:\\\\Users\\\\Lea\\\\Desktop\\\\Doktor\\\\Models\\\\trillsson4\"\n",
    "# learning rate\n",
    "lr = 0.0005\n",
    "# dropout rate\n",
    "dr = 0.3\n",
    "# units dense layer\n",
    "units = 128\n",
    "# size of one batch for trillsson Model\n",
    "batch_size_embedding = 10\n",
    "# size of one batch for CNN\n",
    "batch_size = 1024\n",
    "# L1 regularization parameter used in the dense layers\n",
    "l1 = 0.013\n",
    "# L2 regularization parameter used in the dense layers\n",
    "l2 = 0.0026\n",
    "# maximal number of epochs\n",
    "max_epochs = 250\n",
    "\n",
    "# number of individual runs\n",
    "runs = 250\n",
    "# pictures of first Epoch\n",
    "first_pictures = True\n",
    "# if not None Speaker for Test and Val will not be random\n",
    "# give a List with List like [['OLALT3', 'HBALT3', 'FLALT2', 'CUXALT4'], ['BLALT1', 'BBALT2', 'CWALT', 'ULALT1']]\n",
    "# each List represents an dialect and the first half of each sublist the Speaker for Testing and the second half the speaker for Validation\n",
    "test = None #[['...', '...'], ['...', '...', '...', '...'], ...]\n",
    "# test with dummy-classificator\n",
    "dummy = False\n",
    "# project to TB\n",
    "tb = True\n",
    "log_dir = '...'\n",
    "# Test different Hyperparameters\n",
    "hyper_test = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219c7887",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b005604",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (name_aug != ''):\n",
    "    augment(name_aug, data_path, data_path_aug, aug_perc, aug_num, aug_len, audio_length, test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01e33b9",
   "metadata": {},
   "source": [
    "## DF with all Audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c4e968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speaker = create_speaker_DF(data_path, data_path_aug, name_aug)\n",
    "df_speaker = pd.read_pickle('./All_Files_.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cf77f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b71736",
   "metadata": {},
   "source": [
    "## Extract Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0f3868",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_learn = create_data(model_path, audio_length, batch_size_embedding, '', None, None)\n",
    "if (name_aug != ''):\n",
    "    df_learn_aug = create_data(model_path, audio_length, batch_size_embedding, name_aug, max_length_speaker, max_length_dialect)\n",
    "\n",
    "df_learn = pd.read_pickle('./Data_.pkl')\n",
    "if (name_aug != ''):\n",
    "    df_learn_aug = pd.read_pickle('./Data_' + name_aug + '_aug.pkl')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d17528",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929a72c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if (name_aug != ''):\n",
    "    print(df_learn_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b753cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "getAbsoluteCounts(None)\n",
    "if (name_aug != ''):\n",
    "    getAbsoluteCounts(name_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6445ce6b",
   "metadata": {},
   "source": [
    "### Projection of embeddings to TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42a90562",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tb:\n",
    "    labels1 = np.array(df_learn['dialect'].tolist())\n",
    "    len_1 = len(labels1)\n",
    "    labels2 = np.array(df_learn['speaker'].tolist())\n",
    "    embeddings = np.array(df_learn['trillsson'].values.tolist())\n",
    "    if (name_aug != ''):\n",
    "            labels3 = np.array(df_learn_aug['dialect'].tolist())\n",
    "            labels4 = np.array(df_learn_aug['speaker'].tolist())\n",
    "            embeddings2 = np.array(df_learn_aug['trillsson'].values.tolist())\n",
    "            labels1 = np.concatenate((labels1, labels3), axis=None)\n",
    "            labels2 = np.concatenate((labels2, labels4), axis=None)\n",
    "            embeddings = np.concatenate((embeddings, embeddings2), axis=0)\n",
    "\n",
    "    with open(os.path.join(log_dir, 'metadata.tsv'), \"w\") as metadata:\n",
    "        for i in range(0, len(labels1)):\n",
    "            if i >= len_1:\n",
    "                metadata.write(f'{labels1[i] + \"_\" + labels2[i] + \"_aug\"}\\n')\n",
    "            else:\n",
    "                metadata.write(f'{labels1[i] + \"_\" + labels2[i]}\\n')\n",
    "        \n",
    "    embeddings_tensor = tf.Variable(embeddings)\n",
    "\n",
    "    checkpoint = tf.train.Checkpoint(embedding=embeddings_tensor)\n",
    "    checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))\n",
    "\n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "    embedding.metadata_path = 'metadata.tsv'\n",
    "    projector.visualize_embeddings(log_dir, config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f1ea9b",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b36646c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_learned = pd.DataFrame(columns=['acc_train', 'acc_val', 'acc_test',\n",
    "                                    'loss_train', 'loss_val', 'loss_test',\n",
    "                                    'f1_train', 'f1_val', 'f1_test',\n",
    "                                    'f1_w_train', 'f1_w_val', 'f1_w_test',\n",
    "                                    'speaker_val', 'speaker_test', 'false_names', 'false_speaker', 'false_segments_begin',\n",
    "                                    'false_segments_end', 'false_simplified', 'classes_x', 'classes_true', 'y_test_names', \n",
    "                                    'y_test_speaker'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0965f39b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, runs):\n",
    "    print('Iteration ', i, ' of ' + str(runs))\n",
    "    \n",
    "    if test is None:\n",
    "        test_val = choose(df_speaker)\n",
    "        print(test_val)\n",
    "    else:\n",
    "        test_val = test\n",
    "\n",
    "    if (hyper_test):\n",
    "        lr_test = random.uniform(lr[0], lr[1])\n",
    "        dr_test = random.uniform(dr[0], dr[1])\n",
    "        l1_test = random.uniform(l1[0], l1[1])\n",
    "        l2_test = random.uniform(l2[0], l2[1])\n",
    "        units_test_num = random.randint(0, len(units)-1)\n",
    "        units_test = units[units_test_num]\n",
    "        batch_size_test_num = random.randint(0, len(batch_size)-1)\n",
    "        batch_size_test = batch_size[batch_size_test_num]\n",
    "             \n",
    "    if (hyper_test and df_learn_aug is not None):\n",
    "        list_row, label_mapping = do_all(first_pictures, df_learn, df_learn_aug, test_val, name_aug, i, lr_test, dr_test, units_test, l1_test_conv, l2_test_conv, l1_test, l2_test, batch_size_test, tb, log_dir, dummy, max_epochs)  \n",
    "    elif (df_learn_aug is not None):\n",
    "        list_row, label_mapping = do_all(first_pictures, df_learn, df_learn_aug, test_val, name_aug, i, lr, dr, units, l1, l2, batch_size, tb, log_dir, dummy, max_epochs)   \n",
    "    elif (hyper_test):\n",
    "        list_row, label_mapping = do_all(first_pictures, df_learn, None, test_val, name_aug, i, lr_test, dr_test, units_test, l1_test_conv, l2_test_conv, l1_test, l2_test, batch_size_test, tb, log_dir, dummy, max_epochs)  \n",
    "    else:\n",
    "        list_row, label_mapping = do_all(first_pictures, df_learn, None, test_val, name_aug, i, lr, dr, units, l1, l2, batch_size, tb, log_dir, dummy, max_epochs)\n",
    "    df_learned.loc[len(df_learned)] = list_row\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d38f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_learned.to_pickle('./Results_' + name + '_' + name_aug + '.pkl')\n",
    "df_learned.to_csv('./Results_' + name + '_' + name_aug + '.csv',  sep=';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1401cce",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e95420a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "boxplot('f1_test', name, name_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08231571",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('f1_w_test', name, name_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9c1bfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boxplot('acc_test', name, name_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e431948",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_f1(name, name_aug, label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "912461c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakerFalse(name, name_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1321db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMatrix(name, name_aug, label_mapping, True)\n",
    "confusionMatrix(name, name_aug, label_mapping, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c3b572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (name_base is not None):\n",
    "    compareConfusionMatrix(name, name_aug, name_base, label_mapping, True)\n",
    "    compareConfusionMatrix(name, name_aug, name_base, label_mapping, False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2fc5445",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (name_base is not None):\n",
    "    boxplot_diff('f1_w_test', name_base, name, name_aug)\n",
    "    raincloud_diff('f1_w_test', name_base, name, name_aug)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27db0cef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#compares results base model with new model (two-sided)\n",
    "if (name_base is not None):\n",
    "    U_base, U_aug, p_U, res_T, var_base, var_aug = significant('./Results_' + name_base + '.pkl', './Results_' + name + '_' + name_aug + '.pkl', 'f1_w_test', 'two-sided')\n",
    "    print(\"two-sided U-test: \", f'{p_U:.20f}')\n",
    "    print(\"two-sided T-test: \", f'{res_T.pvalue:.20f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0b9d90",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#tests whether results from base model is less (worse) than from new model\n",
    "if (name_base is not None):\n",
    "    U_base, U_aug, p_U, res_T, var_base, var_aug = significant('./Results_' + name_base + '.pkl', './Results_' + name + '_' + name_aug + '.pkl', 'f1_w_test', 'less')\n",
    "    print(\"one-sided U-test: \", f'{p_U:.20f}')\n",
    "    print(\"two-sided T-test: \", f'{res_T.pvalue:.20f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3974490",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_scores(name, name_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b67ed8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMatrix(name, name_aug + \"_combined\", label_mapping, True)\n",
    "confusionMatrix(name, name_aug + \"_combined\", label_mapping, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9095d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
