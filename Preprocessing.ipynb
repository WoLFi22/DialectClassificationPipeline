{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3e4cff5",
   "metadata": {},
   "source": [
    "## Preprocessing if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bea1a8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parselmouth.praat import call, run_file\n",
    "import pyloudnorm as pyln\n",
    "import noisereduce as nr\n",
    "import tensorflow as tf\n",
    "import soundfile as sf\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import parselmouth \n",
    "import librosa\n",
    "import random\n",
    "import re\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acff4578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path for temporary audio files\n",
    "tmp_path = \"...\\\\tmp.wav\"\n",
    "\n",
    "#path of own praat scripts\n",
    "praat_marksyllables = \"...\\\\marksyllables_own.praat\"\n",
    "praat_changeformants = \"...\\\\changeformants_own.praat\"\n",
    "\n",
    "#path of the parent folder of the audio files\n",
    "DATASET_PATH = \"...\\\\\"\n",
    "\n",
    "#length of one audio segment in seconds\n",
    "length = 10.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4112e75",
   "metadata": {},
   "source": [
    "### Preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9515f92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://superkogito.github.io/blog/2020/04/30/rms_normalization.html\n",
    "def rms_normalize(sig, rms_level=0):\n",
    "    r = 10**(rms_level / 10.0)\n",
    "    a = np.sqrt( (len(sig) * r**2) / np.sum(sig**2) )\n",
    "    y = sig * a\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67282990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_normalize(sig):\n",
    "    y = sig / (max(sig)+0.2)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aefcecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/@poudelnipriyanka/audio-normalization-9dbcedfefcc0\n",
    "def rms_normalize_pln(sig, rms_level=0):\n",
    "    meter = pyln.Meter(16000)\n",
    "    loudness = meter.integrated_loudness(sig)\n",
    "    y = pyln.normalize.loudness(sig, loudness, rms_level)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6082b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/@poudelnipriyanka/audio-normalization-9dbcedfefcc0\n",
    "def peak_normalize_pln(sig, peak_level=0):\n",
    "    y = pyln.normalize.peak(sig, peak_level)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02387793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dc_offset(sig):\n",
    "    y = sig - np.mean(sig)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18b8b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dc_offset_disturb(sig):\n",
    "    disturbance = np.random.uniform(-0.1, 0.1)\n",
    "    y = sig + disturbance\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cb55751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#works better with Loudness/peak normalized audios\n",
    "def get_new_tempo(audio, start, end):\n",
    "    y, sr = librosa.load(new_path, sr=16000, res_type='soxr_vhq')\n",
    "    sig = y[start:end]\n",
    "    path = tmp_path\n",
    "    sf.write(path, sig, 16000, subtype='PCM_16')\n",
    "    sound = parselmouth.Sound(path)\n",
    "    syllables = run_file(sound, praat_marksyllables, -25, 0.3, 2, 'yes', 'yes', capture_output=True)\n",
    "    pattern = r\"Articulation rate \\(number of syllables \\/ phonation time\\): (\\d+\\.?\\d*)\"\n",
    "    match = re.search(pattern, str(syllables))\n",
    "    if match:\n",
    "        articulation_rate = match.group(1)\n",
    "        ar = float(articulation_rate)\n",
    "        if (ar > 2 and ar < 6.5):\n",
    "            #random_ar = random.uniform(2.5, 6)\n",
    "            return ar/6.0\n",
    "        else:\n",
    "            print(syllables)\n",
    "            return 1.0\n",
    "    else:\n",
    "        print(\"Pattern not found\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d22b4706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_new_tempo(sig, tempo):\n",
    "    path = tmp_path\n",
    "    sf.write(path, sig, 16000, subtype='PCM_16')\n",
    "    sound = parselmouth.Sound(path)\n",
    "    new_sound = call(sound, \"Lengthen (overlap-add)\", 75, 300, tempo)\n",
    "    return new_sound.values.flatten()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa331239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_normalize(sig):\n",
    "    new_pitch = 120\n",
    "    #new_pitch = random.randint(90, 160)\n",
    "    path = tmp_path\n",
    "    sf.write(path, sig, 16000, subtype='PCM_16')\n",
    "    sound = parselmouth.Sound(path)\n",
    "    new_sound = call(sound, \"Change gender\", 80, 170, 1.0, new_pitch, 0.0, 1.0)\n",
    "    return new_sound.values.flatten()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "929869a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_normalize2(sig):\n",
    "    new_pitch = 120\n",
    "    new_std = 18\n",
    "    path = tmp_path\n",
    "    sf.write(path, sig, 16000, subtype='PCM_16')\n",
    "    sound = parselmouth.Sound(path)\n",
    "    \n",
    "    pitch = call(sound, \"To Pitch\", 0.0, 80.0, 170.0)\n",
    "    std_pitch = call(pitch, \"Get standard deviation\", 0.0, 0.0, 'Hertz', return_string=True)\n",
    "    pattern = r\"(\\d+\\.?\\d*) Hz\"\n",
    "    match = re.search(pattern, str(std_pitch))\n",
    "    if match:\n",
    "        std_pitch_res = match.group(1)\n",
    "        faktor = new_std/float(std_pitch_res)\n",
    "    else:\n",
    "        print(std_pitch)\n",
    "        print(\"Pattern not found\")\n",
    "        return 0.0, 0  \n",
    "    \n",
    "    new_sound = call(sound, \"Change gender\", 80, 170, 1.0, new_pitch, faktor, 1.0)\n",
    "    return new_sound.values.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47785713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_reduction(sig):\n",
    "    path = tmp_path\n",
    "    sf.write(path, sig, 16000, subtype='PCM_16')\n",
    "    sound = parselmouth.Sound(path)\n",
    "    new_sound = call(sound, \"Remove noise\", 0, 0, 0.025, 80.0, 8000.0, 40.0, 'spectral-subtraction')\n",
    "    return new_sound.values.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4aa63b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_reduction2(sig):\n",
    "    reduced_noise = nr.reduce_noise(y=sig, sr=16000)\n",
    "    return reduced_noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386a63f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preemphasis(sig):\n",
    "    path = tmp_path\n",
    "    sf.write(path, sig, 16000, subtype='PCM_16')\n",
    "    sound = parselmouth.Sound(path)\n",
    "    new_sound = call(sound, \"Filter (pre-emphasis)...\", 1300.807)\n",
    "    return new_sound.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d42daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cubic_root_compression(sig):\n",
    "    #compressed_signal = np.sign(sig) * np.cbrt(np.abs(sig))\n",
    "    compressed_signal = np.sign(sig) * (np.abs(sig) ** (2/3))\n",
    "    return compressed_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cc619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_formants(sig):\n",
    "    path = tmp_path\n",
    "    sf.write(path, sig, 16000, subtype='PCM_16')\n",
    "    sound = parselmouth.Sound(path)\n",
    "    new_sound = run_file(sound, praat_changeformants, 500, 1500, 25000, 0, 0, 5000, 'yes', 'yes', 'no')\n",
    "    return new_sound[0].values.flatten()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516bfb06",
   "metadata": {},
   "source": [
    "### Audio Files in the DATASET_PATH will be replaced by preprocessed ones!!!\n",
    "\n",
    "#### Output:\n",
    "\n",
    "This code snippet preprocesses the audio data by resampling each audio file to a sampling rate of 16kHz, converting them to mono, concatenating multiple audio files into one, and saving them back to their original directory structure. The resulting audio files are saved with a bit-depth of 16.\n",
    "\n",
    "Additionally, if there are multiple audio files within a single folder for a speaker, they are concatenated into a single audio file before preprocessing.\n",
    "\n",
    "Preprocessing steps can be applied before saving the audio files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3e5857",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_classes = glob(DATASET_PATH + '\\\\*', recursive = True)\n",
    "all_speaker = []\n",
    "\n",
    "# list of all classes\n",
    "for dialect in all_classes:\n",
    "    all_speaker = np.concatenate((all_speaker, glob(dialect + '\\\\*', recursive = True)), axis=None)\n",
    "    \n",
    "for path in all_speaker:\n",
    "    audios = tf.io.gfile.glob(path + '\\\\*.wav')\n",
    "    one_audio = []\n",
    "    print(path)\n",
    "    for audio in audios:\n",
    "        # sample to 16kHz\n",
    "        y, sr = librosa.load(audio, sr=16000, res_type='soxr_vhq')\n",
    "        # to mono\n",
    "        librosa.to_mono(y)\n",
    "        # put all Audios of one speaker into one File\n",
    "        one_audio.append(y)\n",
    "        # remove original File\n",
    "        os.remove(audio)\n",
    "    if len(one_audio) < 1:\n",
    "        print('Speaker empty')\n",
    "    else:\n",
    "        one_audio = np.concatenate(one_audio).ravel()\n",
    "        if len(one_audio) < length*sr:\n",
    "            print('Speaker to short!')\n",
    "        else:\n",
    "            #Preprocessing\n",
    "            res_audio = []\n",
    "            sr_length = int(length*16000)\n",
    "            times = len(one_audio)//(sr_length)\n",
    "            for i in range(0, times):\n",
    "                ad = one_audio[i*sr_length:(i+1)*sr_length]\n",
    "                #preprocessing step\n",
    "                #tempo = get_new_tempo(audio, i*sr_length, (i+1)*sr_length)\n",
    "                #y = pitch_normalize(ad)\n",
    "                y = ad\n",
    "                res_audio.append(y)\n",
    "            res_audio = np.concatenate(res_audio).ravel()\n",
    "            # save as wav with a sampling-rate of 16kHz and bit-depth of 16\n",
    "            sf.write(path + '\\\\' + path.split('\\\\')[-1] + '.wav', res_audio, 16000, 'PCM_16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4fe611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
